{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorly as tl\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt \n",
    "from tensorly.decomposition import CP,tucker, parafac\n",
    "from datetime import timedelta, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FR = pd.read_excel('FINANCIAL_RATIOS_NEW.xlsx', index_col =[0], skiprows=[1])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMAT US Equity</th>\n",
       "      <th>COKE US Equity</th>\n",
       "      <th>WDFC US Equity</th>\n",
       "      <th>AAPL US Equity</th>\n",
       "      <th>KLAC US Equity</th>\n",
       "      <th>SEIC US Equity</th>\n",
       "      <th>CSPI US Equity</th>\n",
       "      <th>ALOT US Equity</th>\n",
       "      <th>AMGN US Equity</th>\n",
       "      <th>CAMP US Equity</th>\n",
       "      <th>...</th>\n",
       "      <th>WMT US Equity.4</th>\n",
       "      <th>C US Equity.4</th>\n",
       "      <th>BA US Equity.4</th>\n",
       "      <th>Unnamed: 1109</th>\n",
       "      <th>Unnamed: 1110</th>\n",
       "      <th>Unnamed: 1111</th>\n",
       "      <th>Unnamed: 1112</th>\n",
       "      <th>Unnamed: 1113</th>\n",
       "      <th>BA US Equity.5</th>\n",
       "      <th>HPQ US Equity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-11-10</th>\n",
       "      <td>15.9515</td>\n",
       "      <td>33.4365</td>\n",
       "      <td>18.7771</td>\n",
       "      <td>36.4561</td>\n",
       "      <td>22.4769</td>\n",
       "      <td>30.0052</td>\n",
       "      <td>55.2000</td>\n",
       "      <td>24.3781</td>\n",
       "      <td>20.1813</td>\n",
       "      <td>12.4386</td>\n",
       "      <td>...</td>\n",
       "      <td>193734.9049</td>\n",
       "      <td>248778.9598</td>\n",
       "      <td>67703.1057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67703.1057</td>\n",
       "      <td>109530.9307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-11-17</th>\n",
       "      <td>16.4041</td>\n",
       "      <td>35.7514</td>\n",
       "      <td>18.5600</td>\n",
       "      <td>37.6535</td>\n",
       "      <td>23.9306</td>\n",
       "      <td>31.1099</td>\n",
       "      <td>56.5333</td>\n",
       "      <td>24.1045</td>\n",
       "      <td>19.9203</td>\n",
       "      <td>12.2456</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70786.9893</td>\n",
       "      <td>108928.3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-11-24</th>\n",
       "      <td>16.7663</td>\n",
       "      <td>35.5359</td>\n",
       "      <td>18.5886</td>\n",
       "      <td>40.1886</td>\n",
       "      <td>23.9444</td>\n",
       "      <td>30.7906</td>\n",
       "      <td>56.2000</td>\n",
       "      <td>24.6269</td>\n",
       "      <td>19.9176</td>\n",
       "      <td>12.3509</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70984.6741</td>\n",
       "      <td>108353.1788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-01</th>\n",
       "      <td>16.0511</td>\n",
       "      <td>34.1326</td>\n",
       "      <td>19.7301</td>\n",
       "      <td>40.0526</td>\n",
       "      <td>23.4491</td>\n",
       "      <td>30.4031</td>\n",
       "      <td>58.6667</td>\n",
       "      <td>24.8756</td>\n",
       "      <td>19.0604</td>\n",
       "      <td>16.7442</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70810.7115</td>\n",
       "      <td>108024.5038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-08</th>\n",
       "      <td>16.7210</td>\n",
       "      <td>36.7459</td>\n",
       "      <td>20.2393</td>\n",
       "      <td>38.7105</td>\n",
       "      <td>23.6389</td>\n",
       "      <td>31.2408</td>\n",
       "      <td>57.2000</td>\n",
       "      <td>24.9502</td>\n",
       "      <td>19.1978</td>\n",
       "      <td>17.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71269.3403</td>\n",
       "      <td>108572.2954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-29</th>\n",
       "      <td>14.6285</td>\n",
       "      <td>18.2930</td>\n",
       "      <td>37.8204</td>\n",
       "      <td>25.6062</td>\n",
       "      <td>16.1131</td>\n",
       "      <td>14.5609</td>\n",
       "      <td>36.7068</td>\n",
       "      <td>28.3810</td>\n",
       "      <td>13.8977</td>\n",
       "      <td>499.7665</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88059.0774</td>\n",
       "      <td>38584.7893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-06</th>\n",
       "      <td>14.9135</td>\n",
       "      <td>20.0395</td>\n",
       "      <td>37.4195</td>\n",
       "      <td>25.5461</td>\n",
       "      <td>16.7233</td>\n",
       "      <td>14.5008</td>\n",
       "      <td>36.7068</td>\n",
       "      <td>27.1800</td>\n",
       "      <td>14.0949</td>\n",
       "      <td>499.7665</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88094.5755</td>\n",
       "      <td>39069.3375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-13</th>\n",
       "      <td>14.8286</td>\n",
       "      <td>21.9931</td>\n",
       "      <td>38.1739</td>\n",
       "      <td>23.8943</td>\n",
       "      <td>16.9791</td>\n",
       "      <td>14.3309</td>\n",
       "      <td>36.7068</td>\n",
       "      <td>26.7375</td>\n",
       "      <td>14.5062</td>\n",
       "      <td>499.7665</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75256.0780</td>\n",
       "      <td>38742.7941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-20</th>\n",
       "      <td>14.1128</td>\n",
       "      <td>21.0654</td>\n",
       "      <td>36.2354</td>\n",
       "      <td>22.3480</td>\n",
       "      <td>16.9317</td>\n",
       "      <td>14.3910</td>\n",
       "      <td>36.7068</td>\n",
       "      <td>26.3372</td>\n",
       "      <td>14.7505</td>\n",
       "      <td>499.7665</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71410.4450</td>\n",
       "      <td>36499.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-27</th>\n",
       "      <td>15.8388</td>\n",
       "      <td>23.4234</td>\n",
       "      <td>38.4165</td>\n",
       "      <td>24.3052</td>\n",
       "      <td>18.7380</td>\n",
       "      <td>15.2743</td>\n",
       "      <td>36.7068</td>\n",
       "      <td>26.5690</td>\n",
       "      <td>15.2130</td>\n",
       "      <td>499.7665</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78232.0062</td>\n",
       "      <td>40817.9248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>812 rows × 1115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            AMAT US Equity  COKE US Equity  WDFC US Equity  AAPL US Equity  \\\n",
       "2006-11-10         15.9515         33.4365         18.7771         36.4561   \n",
       "2006-11-17         16.4041         35.7514         18.5600         37.6535   \n",
       "2006-11-24         16.7663         35.5359         18.5886         40.1886   \n",
       "2006-12-01         16.0511         34.1326         19.7301         40.0526   \n",
       "2006-12-08         16.7210         36.7459         20.2393         38.7105   \n",
       "...                    ...             ...             ...             ...   \n",
       "2022-04-29         14.6285         18.2930         37.8204         25.6062   \n",
       "2022-05-06         14.9135         20.0395         37.4195         25.5461   \n",
       "2022-05-13         14.8286         21.9931         38.1739         23.8943   \n",
       "2022-05-20         14.1128         21.0654         36.2354         22.3480   \n",
       "2022-05-27         15.8388         23.4234         38.4165         24.3052   \n",
       "\n",
       "            KLAC US Equity  SEIC US Equity  CSPI US Equity  ALOT US Equity  \\\n",
       "2006-11-10         22.4769         30.0052         55.2000         24.3781   \n",
       "2006-11-17         23.9306         31.1099         56.5333         24.1045   \n",
       "2006-11-24         23.9444         30.7906         56.2000         24.6269   \n",
       "2006-12-01         23.4491         30.4031         58.6667         24.8756   \n",
       "2006-12-08         23.6389         31.2408         57.2000         24.9502   \n",
       "...                    ...             ...             ...             ...   \n",
       "2022-04-29         16.1131         14.5609         36.7068         28.3810   \n",
       "2022-05-06         16.7233         14.5008         36.7068         27.1800   \n",
       "2022-05-13         16.9791         14.3309         36.7068         26.7375   \n",
       "2022-05-20         16.9317         14.3910         36.7068         26.3372   \n",
       "2022-05-27         18.7380         15.2743         36.7068         26.5690   \n",
       "\n",
       "            AMGN US Equity  CAMP US Equity  ...  WMT US Equity.4  \\\n",
       "2006-11-10         20.1813         12.4386  ...      193734.9049   \n",
       "2006-11-17         19.9203         12.2456  ...              NaN   \n",
       "2006-11-24         19.9176         12.3509  ...              NaN   \n",
       "2006-12-01         19.0604         16.7442  ...              NaN   \n",
       "2006-12-08         19.1978         17.0000  ...              NaN   \n",
       "...                    ...             ...  ...              ...   \n",
       "2022-04-29         13.8977        499.7665  ...              NaN   \n",
       "2022-05-06         14.0949        499.7665  ...              NaN   \n",
       "2022-05-13         14.5062        499.7665  ...              NaN   \n",
       "2022-05-20         14.7505        499.7665  ...              NaN   \n",
       "2022-05-27         15.2130        499.7665  ...              NaN   \n",
       "\n",
       "            C US Equity.4  BA US Equity.4  Unnamed: 1109  Unnamed: 1110  \\\n",
       "2006-11-10    248778.9598      67703.1057            NaN            NaN   \n",
       "2006-11-17            NaN             NaN            NaN            NaN   \n",
       "2006-11-24            NaN             NaN            NaN            NaN   \n",
       "2006-12-01            NaN             NaN            NaN            NaN   \n",
       "2006-12-08            NaN             NaN            NaN            NaN   \n",
       "...                   ...             ...            ...            ...   \n",
       "2022-04-29            NaN             NaN            NaN            NaN   \n",
       "2022-05-06            NaN             NaN            NaN            NaN   \n",
       "2022-05-13            NaN             NaN            NaN            NaN   \n",
       "2022-05-20            NaN             NaN            NaN            NaN   \n",
       "2022-05-27            NaN             NaN            NaN            NaN   \n",
       "\n",
       "            Unnamed: 1111  Unnamed: 1112  Unnamed: 1113  BA US Equity.5  \\\n",
       "2006-11-10            NaN            NaN            NaN      67703.1057   \n",
       "2006-11-17            NaN            NaN            NaN      70786.9893   \n",
       "2006-11-24            NaN            NaN            NaN      70984.6741   \n",
       "2006-12-01            NaN            NaN            NaN      70810.7115   \n",
       "2006-12-08            NaN            NaN            NaN      71269.3403   \n",
       "...                   ...            ...            ...             ...   \n",
       "2022-04-29            NaN            NaN            NaN      88059.0774   \n",
       "2022-05-06            NaN            NaN            NaN      88094.5755   \n",
       "2022-05-13            NaN            NaN            NaN      75256.0780   \n",
       "2022-05-20            NaN            NaN            NaN      71410.4450   \n",
       "2022-05-27            NaN            NaN            NaN      78232.0062   \n",
       "\n",
       "            HPQ US Equity  \n",
       "2006-11-10    109530.9307  \n",
       "2006-11-17    108928.3600  \n",
       "2006-11-24    108353.1788  \n",
       "2006-12-01    108024.5038  \n",
       "2006-12-08    108572.2954  \n",
       "...                   ...  \n",
       "2022-04-29     38584.7893  \n",
       "2022-05-06     39069.3375  \n",
       "2022-05-13     38742.7941  \n",
       "2022-05-20     36499.1250  \n",
       "2022-05-27     40817.9248  \n",
       "\n",
       "[812 rows x 1115 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Currently the features are PE, PS, PB, MCAP and PX_LAST need to further improve it with feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_FR = pd.read_excel('FINANCIAL_RATIOS_f.xlsx', index_col =[0])\n",
    "price = None\n",
    "FR_dic = {}\n",
    "FR_list = ['PE', 'PX_LAST', 'PS','PB']\n",
    "n = 0 \n",
    "NUMBER_OF_STOCKS = 220\n",
    "for i,name in enumerate(FR_list) : \n",
    "    FR_dic[name] = (df_FR.iloc[:,n:n+NUMBER_OF_STOCKS]\n",
    "                    .set_index(df_FR.index)\n",
    "                    )\n",
    "\n",
    "    if name not in ['PX_LAST', 'MCAP'] : \n",
    "        FR_dic[name] = (FR_dic[name] - FR_dic[name].mean()) / FR_dic[name].std()\n",
    "        \n",
    "    if name in ['PX_LAST'] :\n",
    "\n",
    "        price = FR_dic['PX_LAST']\n",
    "        FR_dic[name] = np.log(FR_dic[name])\n",
    "        FR_dic[name] = FR_dic[name].diff()\n",
    "    \n",
    "    # if name in ['MCAP'] : \n",
    "    #     FR_dic[name] = FR_dic[name] - FR_dic[name].shift(+1)\n",
    "    \n",
    "    FR_dic[name] = FR_dic[name][1:]\n",
    "    n += NUMBER_OF_STOCKS + 2\n",
    "\n",
    "COLUMN_NAMES = FR_dic['PE'].columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We attempt to predict $AAPL 's cumulative log returns 8 weeks from now based on historical data which has a lookback period of 13 weeks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in FR_dic['PX_LAST'] : \n",
    "    if col.startswith('AAPL') : \n",
    "        y_predict = FR_dic['PX_LAST'][col]\n",
    "\n",
    "AAPL_returns = pd.DataFrame(y_predict).set_axis(['Log Returns'], axis = 1)\n",
    "AAPL_returns['Cumulative Log Returns'] = AAPL_returns['Log Returns'].cumsum()\n",
    "\n",
    "def get_x_week_returns(log_returns, look_back_duration = 13) : \n",
    "    lookforward = 4\n",
    "    sdate = AAPL_returns.index.values[0]\n",
    "    edate = AAPL_returns.index.values[-1]\n",
    "    s = (log_returns\n",
    "     .reset_index()\n",
    "     .iloc[look_back_duration:]\n",
    "    )\n",
    "    x_week_returns = s.rolling(lookforward).sum()\n",
    "    x_week_returns.index = list(pd.date_range(sdate ,edate + pd.to_timedelta(2, unit='D') ,freq='w') - pd.to_timedelta(2, unit='D'))[:-look_back_duration]\n",
    "    return x_week_returns.dropna() \n",
    "\n",
    "\n",
    "def to_simple_return(cum_log_ret) : \n",
    "    return np.exp(cum_log_ret) - 1\n",
    "\n",
    "x_ret = get_x_week_returns(AAPL_returns['Log Returns'])\n",
    "y_train = x_ret\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# AAPL_simple_returns = to_simple_return(AAPL_returns['Cumulative Log Returns'][-1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  3.,   1.,   6.,   7.,  49., 176., 308., 197.,  46.,   2.]), array([-0.50085395, -0.42000946, -0.33916498, -0.25832049, -0.17747601,\n",
      "       -0.09663152, -0.01578703,  0.06505745,  0.14590194,  0.22674642,\n",
      "        0.30759091]), <BarContainer object of 10 artists>)\n",
      "(array([527.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 268.]), array([-1. , -0.8, -0.6, -0.4, -0.2,  0. ,  0.2,  0.4,  0.6,  0.8,  1. ]), <BarContainer object of 10 artists>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.hist(y_arr, bins = 50)\n",
    "\n",
    "# y_arr = y_arr['Log Returns']\n",
    "y_arr = y_train.values\n",
    "print(plt.hist(y_arr))\n",
    "\n",
    "y_arr = y_arr.flatten()\n",
    "y_arr[(y_arr > 0.060)] = 1\n",
    "\n",
    "y_arr[y_arr <= 0.060] = -1\n",
    "\n",
    "print(plt.hist(y_arr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into < -5\n",
    "-5,0\n",
    "0,5\n",
    "> 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TI = pd.read_excel('TECH_NEW.xlsx', skiprows=[0])\n",
    "# df_TI.columns = df_TI.columns.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "TI_dic = {}\n",
    "TI_list = ['WLPR', 'RSI', 'ROC', 'MOM','HURST','BB_PERCENT']\n",
    "n = 1\n",
    "\n",
    "for _, TI in enumerate(TI_list) : \n",
    "    filter_col = [col for col in df_TI if col.startswith(TI)]\n",
    "    TI_dic[TI] = (df_TI[filter_col]\n",
    "                 .set_axis(COLUMN_NAMES, axis=1)\n",
    "                 .set_index(df_TI['Dates'])\n",
    "                 .iloc[:-1]\n",
    "                 .fillna(method = 'ffill')\n",
    "                 )\n",
    "    TI_dic[TI] = (TI_dic[TI] - TI_dic[TI].mean()) / TI_dic[TI].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df_FR = pd.read_excel('FINANCIAL_RATIOS.xlsx', index_col =[0], skiprows=[1,2])\n",
    "# df_PX = pd.read_excel('PRICE_DATA.xlsx', index_col =[0], skiprows=[1,2])\n",
    "\n",
    "\n",
    "# df_PX.drop(list(df_PX.filter(regex='TTWO')), axis=1, inplace = True)\n",
    "# df_PX.drop(list(df_PX.filter(regex='TSCO')), axis=1, inplace = True)\n",
    "# df_PX.drop(list(df_PX.filter(regex='AXTI')), axis=1, inplace = True)\n",
    "# df_PX.drop(list(df_PX.filter(regex='DISH')), axis=1, inplace = True)\n",
    "# df_PX.drop(list(df_PX.filter(regex='TTEC')), axis=1, inplace = True)\n",
    "# df_PX.drop(list(df_PX.filter(regex='ELTK')), axis=1, inplace = True)\n",
    "# df_PX.drop(list(df_PX.filter(regex='LOGI')), axis=1, inplace = True)\n",
    "\n",
    "# df_PX.to_excel('PRICE_DATA_f.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "    # FR_dic[name] = (FR_dic[name] - FR_dic[name].mean()) / FR_dic[name].std()\n",
    "\n",
    "# COLUMN_NAMES = PX_dic['PE'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zackx\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3364: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ft1 =  np.stack(FR_dic.values(), axis=2)\n",
    "ft2 = np.stack(TI_dic.values(), axis=2)\n",
    "feature_tensor = np.dstack((ft1, ft2))\n",
    "                \n",
    "# There is 811-13 datasets to train on\n",
    "# We first apply the tucker decomposition and then vectorize the values.\n",
    "\n",
    "list_of_features = []\n",
    "for i in range(0,len(feature_tensor)-13-3) : \n",
    "    list_of_features.append(feature_tensor[i:i+13, :,:])\n",
    "\n",
    "\n",
    "# Tucker decompose the feature vectors\n",
    "list_of_decomposed_features = []\n",
    "for t_features in list_of_features :\n",
    "    core, factors = (tucker(t_features, rank = [13,20,10]))\n",
    "    list_of_decomposed_features.append(core)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We build a RandomForestRegressor model \n",
    "\n",
    "Random Forests is a supervised machine learning algorithim that uses multiple decision trees in aggregate to help make more stable and accurate predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "X_Cols = [tensor.flatten() for tensor in list_of_decomposed_features ]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_Cols, y_arr)\n",
    " \n",
    "rand_frst_class = RandomForestClassifier(n_estimators= 3000, max_features = 'sqrt', min_samples_split=2, min_samples_leaf = 2, max_depth = 46, bootstrap= False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, max_depth=46, max_features='sqrt',\n",
       "                       min_samples_leaf=2, n_estimators=3000)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_estimators = [2000, 3000, 5000]\n",
    "\n",
    "# max_features = ['auto', 'sqrt']\n",
    "\n",
    "# max_depth = [int(x) for x in np.linspace(10,120,10)]\n",
    "\n",
    "# min_samples_split = [2, 5, 10]\n",
    "\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# bootstrap = [True, False]\n",
    "\n",
    "\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "\n",
    "# 'max_features': max_features,\n",
    "\n",
    "# 'max_depth': max_depth,\n",
    "\n",
    "# 'min_samples_split': min_samples_split,\n",
    "\n",
    "# 'min_samples_leaf': min_samples_leaf,\n",
    "\n",
    "# 'bootstrap': bootstrap\n",
    "\n",
    "\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "# rf = RandomForestClassifier()\n",
    "\n",
    "# # Using 5 fold cross validation\n",
    "# # Search across 100 different combintations and use all available cores\n",
    "\n",
    "# rf_random = RandomizedSearchCV(\n",
    "#     estimator = rf,\n",
    "#     param_distributions= random_grid,\n",
    "#     n_iter = 100, \n",
    "#     cv = 3, \n",
    "#     verbose= 4,\n",
    "#     random_state=35,\n",
    "#     n_jobs = - 1\n",
    "#                         )\n",
    "\n",
    "# rf_random.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "# rand_frst_reg.fit(X_train,Y_train)\n",
    "\n",
    "rand_frst_class.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation : Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6733668341708543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[128,   6],\n",
       "       [ 59,   6]], dtype=int64)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "\n",
    "# print('Random grid: ', random_grid, '\\n')\n",
    "\n",
    "# print('Best Parameters: ', rf_random.best_params_, ' \\n')\n",
    "\n",
    "# print(rf_random.best_score_)\n",
    "# print('bro')\n",
    "# predictions = rf_random.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "#Classification \n",
    "# print(len(X_test))\n",
    "\n",
    "# np.array()\n",
    "# predict_1 = rand_frst_class.predict(X_train)\n",
    "# print(accuracy_score(Y_train,predict_1))\n",
    "\n",
    "prediction = rand_frst_class.predict(X_test)\n",
    "print(accuracy_score(Y_test, prediction))\n",
    "confusion_matrix(Y_test, prediction)\n",
    "\n",
    "\n",
    "# np.set_printoptions(precision=2, suppress=Tru/e)\n",
    "\n",
    "\n",
    "# predictions = rf_random.predict(X_test)\n",
    "\n",
    "# print(predictions)\n",
    "\n",
    "# print(np.array(Y_test['Log Returns']))\n",
    "# errors  = abs(predictions - Y_test['Log Returns'])\n",
    "\n",
    "# print('Average absolute error:', round(np.mean(errors), 2), 'degrees.')\n",
    "\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "# mape = 100 * (errors / Y_test)\n",
    "# Calculate and display accuracy\n",
    "# accuracy = 100 - np.mean(mape)\n",
    "# print('Accuracy:', round(accuracy, 2), '%.')\n",
    "\n",
    "\n",
    "\n",
    "# Plot of the predicted log_returns vs actual returns\n",
    "# plt.plot(Y_test['Log Returns'])\n",
    "# plt.plot(predictions, 'o')\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2000, 5, 1, sqrt, 95 False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6733668341708543\n",
      "[-1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1.]\n"
     ]
    }
   ],
   "source": [
    "print(np.count_nonzero(Y_test == -1) / len(Y_test))\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a43ecbfcacf4711d3582acb40aab0235755f43066e5aed5394aa187054bb06d3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
